---
layout: post
title: "【计网】Ch5：运输层-1"
author: LJC
tags:
- network
date: 2022-10-31 13:12 +0800
toc: true
---

# 运输层 (Transport layer) - Part1

此前所介绍的 物理层，数据链路层，网络层 共同解决了将主机通过异构网络互连起来所面临的问题，**实现了主机到主机的通信**。但实际上，在计算机网络中**进行通信的真正实体是 位于通信两端主机中的进程**。

![tl01.png](/images/net/tl01.png "TL")

## 1. 运输层：为进程通信提供服务

【运输层的任务】：为应用进程的通信提供服务，即**如何运行在不同主机上的应用进程提供直接的通信服务是运输层的任务**，运输层协议又称为端到端协议，应用范围是 **进程到进程，即【端到端】**。

![tl02.png](/images/net/tl02.png "TL2")
 
注意图中的虚线，表示数据的传输方向。如图，不同的进程如何区分？ 

**运输层使用不同的端口来对应不同的应用进程**，然后通过网络层及下层来传输报文。接收方的运输层**通过不同端口**，将收到的应用层报文交付给应用层中相应的应用进程。这里的【**端口**】并不是物理意义上的实体端口，而是指用来**区分不同应用进程**的**标识符**。

> 为了简单起见，在学习运输层时，简单地认为**运输层直接为 应用进程间的逻辑通信提供服务**。


运输层向高层用户屏蔽了下面网络核心的细节（如网络拓扑，路由选择协议等），它让进程看见的就好像两个运输层实体之间有一条端到端的逻辑通信信道。根据应用需求的不同，运输层为应用层提供了两种不同的运输协议，即 **面向连接的 TCP 和无连接的 UDP** ，这两种协议就是运输层的主要内容。

### 端到端 和 点到点

**端到端 end-to-end** ：假设将数据从A传送到E，中间可能经过 **A**→B→C→D→**E**，但运输层并不知道 B/C/D 的存在。对它来说：从A传送到E，那只关注A和E（两端），只认为报文数据是从一端 A 到另一端 E 的，这就是端到端。
- 如图中蓝色的逻辑直连通道
- ![tl03.png](/images/net/tl03.png "端到端")

**点到点**：以网络层为例，它要关心从A点去往下一个点（涉及到路由选择等）

端到端和点到点的区别与联系：
- 端到端由若干的点到点实现和组成，它是建立在点到点的基础之上的。
- 直白说，**传输层及以上使用端到端**，**网络层及以下使用点到点传输**。
    - （路由器是分水岭，它最高到网络层）
- 从 点到点 到 端到端，也是封装的体现；

------

## 2. 运输层端口号，复用与分用

### **端口号**

> 运输层为进程通信提供服务，不同进程用不同端口号区分。

在 PC 上，不同进程用 **进程标识符 PID** 来区分。但因特网上的主机运行的不同操作系统（Win，Mac，Linux，Unix）使用的**进程标识符格式也不同**。那么，为了让进程之间通信，就要**统一对 TCP/IP 体系的应用进程 作标识**。

TCP/IP 体系的运输层使用 **端口号** 来区分 应用层的不同应用进程。
- **端口号（16 bit）**：取值范围 **0~65535** ，【3种】

    - 熟知端口号：0~1023，指派给 TCP/IP 体系中最重要的一些应用协议，如 FTP(21/20)，HTTP(80)，DNS(53)；

    - 登记端口号：1024~49151，为没有熟知端口号的应用程序使用。使用必须在互联网协会登记，防止重复。如 Microsoft RDP 远程桌面使用 3389 ，MySQL (3306) 。
    
    - 短暂端口号：49152~65535，留给客户进程选择暂时使用。当服务器进程收到客户进程的报文时，就知道了客户进程所使用的动态端口号，通信结束后该端口号可供其他客户进程以后使用。

- 注意，**端口号只具有本地意义**，即端口号只是为了（在TCP/IP体系下）**标识本计算机应用层中的各进程**，在因特网中，**不同计算机中的相同端口号是没有联系的**。

<br/>

### 发送方复用 和 接收方分用

如下图：

- 对发送方而言：
    - 运输层：不同端口号的应用进程 **复用（都用）** **UDP 和 TCP 协议**封装，再交给网络层；
    - ↓
    - 网络层：UDP用户数据报 和 TCP报文 **复用（都用）** IP 协议 封装成 IP 数据报；
        - IP 数据报头中 [协议字段](https://jeremy1lee.github.io/2022/10/29/network-ch4-2/#%E4%B8%89%E5%9B%9B%E4%BA%94%E8%A1%8C) 表明该数据载荷是运输层用的哪个协议数据单元（6/17）；

- ![tl04.png](/images/net/tl04.png "发送方的复用和接收方的分用")

- 对接收方而言：
    - 网络层： IP 数据报 **分用（分别用）** IP 协议 上交给 UDP 和 TCP ；
        - 依然由 IP 数据报头中 协议字段表明该数据载荷是运输层用的哪个协议数据单元（6/17）区分；
    - ↓
    - 运输层：UDP和TCP **分用（分别用）** 不同端口号，把数据交付给上层相应的应用进程；

**应用层常用协议** 使用的 运输层**端口号**：
- ![tl05.png](/images/net/tl05.png "端口号")

举例如图：一个以太网中有 DNS 服务器，web服务器，PC，交换机互连。

![tl06.png](/images/net/tl06.png "场景")

- 在 PC 中使用浏览器访问web服务器中的内容，输入域名URL后，**DNS 客户端进程**会发送一个 DNS 查询请求报文
- 该报文是 进程到进程，属于运输层，需要使用 UDP 协议：
    - 源端口号 为一个登记端口号，假设是 49152；
    - 目的端口 设置为 应用层DNS协议使用的运输层端口号 53；
    - ![tl07.png](/images/net/tl07.png "端口号")
- 封装在 IP 数据报中，再封装到帧中，发送给 DNS 服务器
    - 服务器拆封后，根据端口号53，交付给 DNS 服务器端进程
    - 发回一个 DNS 响应报文，这次目的地址是短暂端口号；
    - ![tl08.png](/images/net/tl08.png "回文")
- 主机收到web服务器的ip地址，HTTP（端口号80）进程向web服务器发送请求报文：
    - ![tl09.png](/images/net/tl09.png "HTTP")
- web 服务器回文
    - ![tl10.png](/images/net/tl10.png "HTTP 回文")
- 主机进程解析 HTTP 相应报文，在浏览器中显示，看到网页内容。

---------------------

## 3. 用户数据报 UDP 和 传输控制 TCP 的对比

TCP/IP 协议体系中运输层的两个重要协议，使用频率仅次于 IP 协议。应用层的某些协议用运输层的UDP提供的服务，另一些用到TCP提供的服务。

**用户数据报协议 UDP (User Datagram Protocol)** 和 **传输控制协议 TCP (Transmission Control Protocol)**

> 注意，平时说的 "数据报" 一般指 UDP 数据报，因为 UDP 是按数据报传输的，而 TCP 是按字节流传输的；

### ① 发送数据：UDP 无连接，TCP 面向连接

- UDP 可以随时发送数据，而 TCP 数据传输之前必须经过**三报文握手**建立 TCP 连接，然后再数据传输，完成传输后，必须**四报文挥手**来释放 TCP 连接。
    - 所以才叫 **UDP 无连接， TCP 面向连接**，也就是说 UDP 不需要虚电路，而 TCP 需要建立**虚电路**（虚的，指逻辑上的，一种形象的表达而已）
    - ![tl11.png](/images/net/tl11.png "UDP 和 TCP")

- UDP 支持单播，组播，广播（一对一，一对多，一对全），**TCP 仅支持 单播**（一对一）。

<br/>

### ② 处理应用报文：UDP 面向应用报文，TCP 面向字节流

- UDP 直接给应用层报文加一个 UDP 首部，成为 UDP 用户数据报，然后发送；
    - 接收方去掉UDP 首部，将应用层报文交付给应用进程；
    - UDP 既不合并，也不拆分，保留报文的边界；
- **UDP 是面向应用报文的**
    - ![tl12.png](/images/net/tl12.png "UDP 和 TCP -2")

- TCP 把应用进程交付下来的数据块仅看成一连串的无结构字节流，TCP 并不知道这些字节流的含义，**仅编号**并**存储**在自己的发送缓存中；
    - TCP 根据发送策略，从发送缓存中提取一定数量的字节构建 TCP 报文段并发送；
    - 接收方 TCP ：
        - 一方面从接收到的 TCP 报文段中取出数据载荷，放在接收缓存中；
        - 一方面将接收缓存中的一些字节交付给应用进程；
    - TCP 并不保证 发送的数据块和接收的数据块 具有 <u>对应大小</u> 的关系
        - 例如发送方进程给了10个数据块，但接收方的 TCP 可能只用了四个数据块就把收到的字节流交付给了上层的应用进程（发送和接收方的差异）
        - 但接受方收到的字节流**必须**和发送方进程发出的字节流**完全一样**
            - 当然，接收方的应用进程必须有能力识别收到的字节流，并还原成有意义的应用数据
            - TCP 两端可以同时发送和接收（全双工）
- **TCP 是面向字节流的**，也是实现可靠传输，流量控制，拥塞控制的基础

<br/>

### ③ 提供服务：UDP不可靠，TCP可靠

- UDP 向上层提供无连接不可靠传输服务
    - 若误码，直接被丢弃
    - 路由器丢弃就丢弃了，发送方也不会重发
- UDP 特性使其 适用于 IP 电话，视频会议，直播，游戏等；

- ![tl13.png](/images/net/tl13.png "UDP 和 TCP - 3")

- 尽管 IP 协议也提供无连接不可靠的服务，但只要运输层用 TCP ，就可向其上层提供面向连接的可靠传输服务。
    - 想象成 建立了一个基于 TCP 连接的**可靠**信道进行传输（图中绿色信道），不会出现差错。（回想一下 [停止等待，回退N帧，选择重传](https://jeremy1lee.github.io/2022/10/21/network-ch3-1/#4-%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E5%8F%8A%E4%B8%89%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95)）
- TCP 适用于**文件传输**。

> 当时提到，停止等待，回退N帧，选择重传 这三种可靠传输实现机制的原理不仅限于数据链路层，可以应用到计算机网络体系结构的各层协议中。运输层就是其一。

<br/>

### ④ 报文段首部：UDP简单，TCP复杂

- UDP 报文首部只有四个字段，每个字段长两个字节，只是添加了用于区分应用进程的端口。

- ![tl14.png](/images/net/tl14.png "UDP 和 TCP - 4")

- TCP 报文段由首部和数据载荷两部分构成：
    - TCP 首部较复杂，最小 20 字节，最大 60 字节；
        - 因为要实现可靠传输，流量控制，拥塞控制等服务，所以复杂，字段多，长度长；
        - UDP 要实现一些功能也可以自己定义报文，功能多了，报文相应变得复杂

--------------------

## 4. TCP 流量控制：滑动窗口协议 Sliding Window Protocol

> 都希望数据传输的更快点，但如果太快了，接收方可能来不及接收，造成数据丢失。

**流量控制 (Flow Control)** 就是让发送方的发送速率不要太快，让接收方来得及接收。利用**滑动窗口协议**可以方便地在 TCP 连接上实现 **接收方对发送方的流量控制**。

如图， A 待发送数据的字节序号已显示，一格100字节。假设 B 和A建立TCP连接时，B通知A：其接收窗口为 400 ，因此 A 将自己的**发送窗口**也设置为 400 。【**这里暂时不考虑拥塞窗口**】
- 即：A 未收到 B 的确认时可将序号落入发送窗口中的全部数据发送出去；
- ![tcp01.png](/images/net/tcp01.png "tcp01")

主机 B 给 A 发送 TCP 确认报文，通知其前200个已正确收到，并告知把接收窗口调整成了300 。
- ![tcp02.png](/images/net/tcp02.png "tcp02")

【重要，滑动操作】主机 A **先将自己的发送窗口向前滑动，目的是把已发送的数据移出窗口**，**然后根据B的流量控制通知，将自己的发送窗口宽度也调整为 300**。【先滑，后改宽度】如图：
- ![tcp02-1.png](/images/net/tcp02-1.png "tcp02-1")
- 201-300已经发送了，直到重传计时器超时，会重传
- 可将1-200字节的缓存删除，因为已经收到了确认
- 还能发送300-500的两段

如图，已经发完窗口内的所有数据，在等到确认之前不能发送新数据了；
- ![tcp03.png](/images/net/tcp03.png "tcp03")

B 给 A 回复确认，ack=501说明前500个都正确收到了。此时 B 进行了第二次流量控制，窗口调整为 100 。A 收到后依然是**先**把 300 宽度的往后**滑**  ，**再调整**成 100 。
- ![tcp04.png](/images/net/tcp04.png "tcp04")

现在主机 B 的缓存不够了，它继续控制流量，不让 A 发送了：
- ![tcp05.png](/images/net/tcp05.png "tcp05")

主机 B 又腾出了一部分缓存，它让 A 发送了，把窗口调整成 300 ：
- ![tcp06.png](/images/net/tcp06.png "tcp06")
- 但是，假设B给A的报文丢失了，如果不采取措施，将一直死锁：

为了避免这种情况，显然要在收到 0 窗口通知后，加一个**持续计时器**，超时了 A 就**发送一个零窗口探测报文**，只携带 1 字节的数据。B 在确认探测报文段时，给出自己现在的**接收窗口值**：
- ![tcp07.png](/images/net/tcp07.png "tcp07")

- 如果接收窗口仍然是 0：说明B还没让A发，重新启动计时器继续计时；
- 如果接收窗口是不是 0 ：打破了死锁

TCP规定：**即使接收窗口是0，也必须接受零窗口探测报文段，确认报文段，以及携带紧急数据的报文段**。
- 零窗口探测报文段不怕丢失，它也有重传计时器。即使丢失，在计时器超时后重发零窗口探测报文段；

------------------------

## 5. TCP 的拥塞控制（四种算法）

**拥塞 (Congestion)**：某段时间，**对网络某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏**的情况。
- 网络资源：链路带宽（容量），交换机的缓存等都是网络资源；

若**出现拥塞而不加以控制**，整个网络的**吞吐量（从网络输出的分组）将随输入负荷增大而下降**。
- 理想的拥塞控制：输入达到一定程度，吞吐量恒定维持在最大值。例如输入到网络的某些分组被某个节点丢弃了。
- 实际的情况：随负载增大，吞吐量的斜率逐渐减小，即吞吐量还没饱和，就已经有分组被丢弃了。
- ![tcp08.png](/images/net/tcp08.png "tcp08")

<br/>

**TCP 四种拥塞控制**

> 假定：1）在场景中数据单方向传输，即一边只传送确认报文；2）接收方总是有足够大的缓存空间，即发送方发送窗口的大小由网络的拥塞程度决定。3）以最大报文段MSS的个数为讨论单位，而不是以字节为单位。

首先，发送方需要维护三个状态变量：

![tcp09.png](/images/net/tcp09.png "tcp维护的状态变量")

1. 发送方维护 **拥塞窗口 cwnd** 状态变量，其值取决于网络的拥塞程度，并动态变化：
    - 拥塞窗口 **cwnd 的维护原则**：
        - 只要网络**没有出现拥塞**，拥塞窗口就再**增大**一些；
        - 只要网络**出现拥塞**，拥塞窗口就**减少**一些；
    - **判断出现网络拥塞的依据**：没有按时收到应当到达的确认报文（即**发生超时重传**）
2. **拥塞窗口 swnd = 发送窗口 cwnd**：即，发送方将拥塞窗口 cwnd 作为 发送窗口 swnd ；
3. 发送方还要维护**慢开始门限 ssthresh** 状态变量：
    - 拥塞窗口 cwnd < ssthresh 时，使用**慢开始**算法；
    - 拥塞窗口 cwnd > ssthresh 时，停用慢开始算法，转而使用**拥塞避免**算法；
    - cwnd = ssthresh 时，慢开始算法和拥塞避免算法 都可以用；

**传输轮次**：发送方给接收方发送数据报文段后，接收方给发送方发回相应的确认报文段。
- 一个传输轮次经历的时间就是 **往返时间**（并不恒定）。
- 使用传输轮次：为了强调**把拥塞窗口所允许发送的报文段**都连续发送出去，并收到了对已发送的最后一个报文段的确认。（无论一次性发几个，都是一轮）
拥塞窗口：随 网络拥塞程度 和 使用的拥塞控制算法 动态变化。
- TCP 双方建立逻辑连接关系时，设置拥塞窗口为 1 ，慢开始门限初始值为 16 。

<br/>

### 慢开始 和 拥塞避免

**（一）慢开始：指数增长**

执行慢开始算法时，发送方每收到一个对新报文段的确认时，就把拥塞窗口值 +1，然后进行下一轮传输，当拥塞窗口值增长到慢开始门限值时，**就改为执行拥塞避免算法**。

> 由于拥塞窗口 swnd = 发送窗口 cwnd，拥塞窗口值是几就能发送几个数据报文段。

- 开始，第一轮发1个报文段，回一个报文段；
- 然后发送窗口=2，发2个报文段，回2个报文段；
- 发送窗口=4，发4个报文段，回4个报文段；
- 发送窗口=8，发8个报文段，回8个报文段；
- 发送窗口=16， 16 = 慢开始门限，将执行拥塞避免算法；
    - ![tcp10.png](/images/net/tcp10.png "tcp-慢开始")

**（二）拥塞避免算法：拥塞窗口值每次加1**

- 发送窗口=16，发16个报文段，回16个报文段；
- 发送窗口=17，发17个报文段，回17个报文段；
- 发送窗口=18，发18个报文段，回18个报文段；
- .......
- 发送窗口=24，发24个报文段....，

**超时重传的处理：**

假设**在传输过程中丢失了几个**，必然会造成发送方对这些报文段的 <mark>超时重传</mark> ；
- 发送方判断网络很可能**出现了拥塞**，将进行以下工作：
    - ① 将 **慢开始门限 更新为发生拥塞（发生超时）时 拥塞窗口值的一半**；
    - ② 将 **拥塞窗口值 减小为 1 ，并重新开始执行 慢开始算法**；
        - 对本例：
        - 慢开始门限 = 24/2 = 12
        - 拥塞窗口 = 发送窗口 = 1；
    - ![tcp11.png](/images/net/tcp11.png "tcp-拥塞避免")

**现在又回到了慢开始算法，然后到拥塞避免，然后又回到慢开始...**

- 发送窗口=1，发1个报文段，回1个报文段；
- .................
- 发送窗口=12， 12 = 慢开始门限，将执行拥塞避免算法；
    - ![tcp12.png](/images/net/tcp12.png "tcp-慢开始2")

这一部分的过程如下：
![tcp13.png](/images/net/tcp13.png "tcp-例1)

总之，**慢开始**是指：一开始向网络注入的报文段较少，而不是指拥塞窗口值增长的慢；**拥塞避免**也不是指完全能够避免拥塞，而是指在拥塞避免阶段将拥塞窗口值控制成线性规律（此前是指数），使网络不那么容易出现拥塞。
- 慢开始 和 拥塞避免 是1988提出的TCP拥塞控制，此后又增加了两个新机制：
    - 有时个别报文在网络中**丢失**，但实际上网络**没发生拥塞**；   
        - 这将导致发送方超时重传，并误以为网络发生了拥塞（上述例子），误减小了发送窗口，实际上没必要减小发送窗口；

<br/>

### 快重传 和 快恢复

- 采用 **快重传** 算法，可以**让发送方尽早直到发生了个别报文段的丢失**。
    - 快重传就是使发送方尽快进行重传，而不是等超时重传计时器超时再重传。（熟悉吗？这也是网络层 RIP 协议的问题：[坏消息传的慢](https://jeremy1lee.github.io/2022/10/29/network-ch4-2/#rip-%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98)的解决方法之一）
        - 接收方不要等到自己发送数据时才想起来确认，要立即发送确认；
        - 即使收到了失序的报文段，也要立即发出对已收到的报文段的重复确认；
        - 发送方一旦**收到 3 个连续的重复确认**，就将相应的报文段**立即重传**，而不是等该报文段的超时重传计时器超时再重传；
        - 对于个别丢失的报文段，发送方**不会出现超时重传**（而是快重传），也就不会误以为出现了拥塞，保持发送窗口不会一下子变成1，使整个网络吞吐量提高 20% ；

如图，发1号报文段，接收方回1号的确认报文。在收到1号的确认之前就可以把2号报文段发出去了；

如果3号报文段丢失了，自然不会有确认报文。

- 发送方还继续发 4 号报文，但接收方发现**不是按序到达**的报文段，因此发回**针对2号报文段的重复确认1**：这表明 “其应该收到3号，但收到的是未按序到达的报文段”。

- 在收到这条信息（重复确认1）之前，发送方还会发送 5 号报文段，但接收方发现**不是按序到达**的报文段，因此发回**针对2号报文段的重复确认2**：这表明 “其应该收到3号，但收到的是未按序到达的报文段”。

- 在收到这条信息（重复确认2）之前，发送方还会发送 6 号报文段，但接收方发现**不是按序到达**的报文段，因此发回**针对2号报文段的重复确认3**：这表明 “其应该收到3号，但收到的是未按序到达的报文段”。

- 这样，发送方会收到 **三个**连续的对 2 号报文段的重复确认：就立即重传3号报文段。接收方收到后，给发送方发回**针对 6 号报文段的确认** 表明序号 6 及以前的报文都正确接收了。这样不会继续造成对 3 号报文段的超时重传。

<br/>

**快恢复 的实现**

发送方一旦**收到三个重复确认**，就知道现在只是丢失了个别报文段，于是不**启动慢开始算法**，而是**执行快恢复算法**。
- **发送方将 慢开始门限值 和 拥塞窗口值 调整为当前窗口的一半**，回去**执行拥塞避免算法**
- 也有的快恢复实现是把快恢复开始时的 拥塞窗口值再增大一些，即 拥塞窗口值等于新的 慢开始门限 +3；
    - 因为这三个报文段不用再发了，已经在接收方的缓存里了；
    - 少发三个，因此可以适当扩大一些拥塞窗口；

综上所述， TCP 的**拥塞控制过程**如下图所示：

![tcp14.png](/images/net/tcp14.png "tcp-拥塞控制")

-------------------

## 6. TCP 超时重传时间的选择

超时重传时间的选择是 TCP 最复杂的问题之一。

如图，A/B已经建立了TCP连接，A给B发消息后记下时间，等收到B的确认后又记下时间，二者之差就是往返时间RTT0 。
- ![tcp15.png](/images/net/tcp15.png "tcp-超时重传")

- 现在试想如果将超时重传时间RTO设置的比超时重传时间小：
    - ![tcp16.png](/images/net/tcp16.png "tcp-超时重传-1")
    - 显然会有不必要的重传；
- 如果将超时重传时间RTO设置的 远大于 超时重传时间：
    - ![tcp17.png](/images/net/tcp17.png "tcp-超时重传-2")

综上，超时重传时间 RTO 的值应该**略大于 报文段往返时间 RTT** 的值；

> 如果往返时间不固定呢？

显然如果每次的往返时间固定，那超时重传时间也很简单，但互联网网络环境恰恰不同，每次的往返时间不确定，如果再用旧的重传时间想，就不对了，如图：
- ![tcp18.png](/images/net/tcp18.png "tcp-超时重传-3")

**不能直接使用某次测量得到的RTT样本来计算超时重传时间 RTO**，为了得到比较**平滑**的往返时间，我们可以计算**加权平均往返时间 RTTs**。
- 也就是说，随着发送报文和接收确认，每次都能得到一个往返时间，每次都加入到公式中计算新的RTTs 值。
    - 公式如下：
    - ![tcp19.png](/images/net/tcp19.png "tcp-RTTs计算公式")
- 综上，超时重传时间 RTO 的值应该**略大于 加权平均往返时间 RTTs** 的值；
- 具体略大多少呢？这个略大的值也是平滑的自适应过程，如下图右所示：
    - ![tcp20.png](/images/net/tcp20.png "tcp-RTTs计算公式")
    - 都是基于每个报文样本进行计算的；

> 如果有不理想的情况呢？

问题又来了，往返时间RTT的测量也比较复杂，上面也只考虑了正确发送与正确接收的理想情况，实际情况肯定不会每次都理想，包括发送报文丢失（左），确认报文来的慢了（右）
- ![tcp21.png](/images/net/tcp21.png "不理想情况")

也就是说，发送方出现超时重传时，再收到确认报文段时，是无法判断出是对原报文段的确认还是对重传报文段的确认，即无法准确测量出RTT，影响了RTO计算。

Karn算法：计算加权平均往返时间RTTs时，**只要报文段重传了，就不采用其往返时间 RTT 样本**。即出现重传时，不重新计算RTTs，进而RTO也不会重新计算。

> 但是又带来了新问题：假设报文段突然在接下来一段时间里时延增大了很多，且将保持这种时延。那么在原有的重传时间设置下不会在重传前收到报文段。而且也不考虑这些样本，重传时间也不会更新，报文段将被反复重传。

因此对Karn算法修正：**报文每重传一次，就把超时重传时间 RTO 增大一些**。典型做法是把RTO值增大为2倍。

综上所述， TCP 的**超时重传过程**如下图所示：

![tcp22.png](/images/net/tcp22.png "tcp-超时重传")

----------------
